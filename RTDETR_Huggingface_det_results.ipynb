{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import os\n",
        "import math\n",
        "import random\n",
        "\n",
        "def plot_rtdetr_predictions(model, dataset, processor, class_names, device=\"cuda\", num_images=24):\n",
        "    model.eval().to(device)\n",
        "    cols = 4\n",
        "    rows = math.ceil(num_images / cols)\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 4, rows * 3), dpi=150)\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    # Define distinct BGR colors for each class\n",
        "    colors = [\n",
        "        (255, 0, 0),     # Red\n",
        "        (0, 255, 0),     # Green\n",
        "        (0, 0, 255),     # Blue\n",
        "        (255, 255, 0),   # Cyan\n",
        "        (255, 0, 255),   # Magenta\n",
        "        (0, 255, 255),   # Yellow\n",
        "        (128, 128, 0),   # Olive\n",
        "        (128, 0, 128),   # Purple\n",
        "        (0, 128, 128),   # Teal\n",
        "        (128, 128, 128)  # Gray\n",
        "    ]\n",
        "    class_colors = {i: colors[i % len(colors)] for i in range(len(class_names))}\n",
        "\n",
        "    # Select random indices from dataset\n",
        "    all_indices = random.sample(range(len(dataset)), min(num_images, len(dataset)))\n",
        "\n",
        "    for i, idx in enumerate(all_indices):\n",
        "        if hasattr(dataset, 'base_dataset'):\n",
        "            pil_img, _ = dataset.base_dataset[idx]\n",
        "            orig_img = np.array(pil_img.convert(\"RGB\"))\n",
        "            img_tensor = processor(images=pil_img, return_tensors=\"pt\").pixel_values.to(device)\n",
        "        else:\n",
        "            print(\"Base dataset not found. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(img_tensor)\n",
        "\n",
        "        height, width = orig_img.shape[:2]\n",
        "        results = processor.post_process_object_detection(\n",
        "            outputs=outputs,\n",
        "            target_sizes=torch.tensor([[height, width]], device=device),\n",
        "            threshold=0.1\n",
        "        )[0]\n",
        "\n",
        "        draw_img = cv2.cvtColor(orig_img, cv2.COLOR_RGB2BGR)\n",
        "        height2, width2, channels = draw_img.shape\n",
        "        if width2 > 800:\n",
        "            fondsize = 3\n",
        "            fondthickness = 4\n",
        "            linethickness = 7\n",
        "        else:\n",
        "            fondsize = 1\n",
        "            fondthickness = 1\n",
        "            linethickness = 2\n",
        "\n",
        "        for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
        "            x1, y1, x2, y2 = map(int, box.tolist())\n",
        "            class_id = label.item()\n",
        "            if class_id >= len(class_names):\n",
        "                continue  # skip invalid class id\n",
        "            color = class_colors.get(class_id, (255, 255, 255))\n",
        "            label_text = f\"{class_names[class_id]}: {score:.2f}\"\n",
        "            cv2.rectangle(draw_img, (x1, y1), (x2, y2), color, linethickness)\n",
        "            cv2.putText(draw_img, label_text, (x1, max(y1 - 5, 15)),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, fondsize, color, fondthickness, cv2.LINE_AA)\n",
        "\n",
        "        draw_img = cv2.cvtColor(draw_img, cv2.COLOR_BGR2RGB)\n",
        "        axes[i].imshow(draw_img, interpolation='none')\n",
        "        axes[i].axis(\"off\")\n",
        "        axes[i].set_title(f\"Image {i + 1}\")\n",
        "\n",
        "    for i in range(num_images, len(axes)):\n",
        "        axes[i].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "JhpdpE0oLQbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 50 epochs\n",
        "model_name = \"PekingU/rtdetr_r101vd_coco_o365\"\n",
        "processor = AutoProcessor.from_pretrained(model_name)\n",
        "model = AutoModelForObjectDetection.from_pretrained(\"datasets/detr_surgical_best_model50\")\n",
        "class_names = ['no', 'Grasper', 'Harmonic_Ace', 'Myoma_Screw',\n",
        "               'Needle_Holder', 'Suction', 'Trocar']\n",
        "\n",
        "plot_rtdetr_predictions(\n",
        "    model=model,\n",
        "    dataset=valid_processed,\n",
        "    processor=processor,\n",
        "    class_names=class_names,\n",
        "    device=\"cuda\",\n",
        "    num_images=100\n",
        ")"
      ],
      "metadata": {
        "id": "r7vs2OhawfzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"PekingU/rtdetr_r101vd_coco_o365\"\n",
        "processor = AutoProcessor.from_pretrained(model_name)\n",
        "model = AutoModelForObjectDetection.from_pretrained(\"datasets/detr_surgical_best_model\")\n",
        "class_names = ['no', 'Grasper', 'Harmonic_Ace', 'Myoma_Screw',\n",
        "               'Needle_Holder', 'Suction', 'Trocar']\n",
        "\n",
        "plot_rtdetr_predictions(\n",
        "    model=model,\n",
        "    dataset=valid_processed,\n",
        "    processor=processor,\n",
        "    class_names=class_names,\n",
        "    device=\"cuda\",\n",
        "    num_images=100\n",
        ")"
      ],
      "metadata": {
        "id": "VtVM8-HsLUNV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}